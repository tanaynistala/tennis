{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [2] # range(1, 6)\n",
    "frame_skip = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for id in video_ids:\n",
    "    with open(f'data/labels/video{id}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.split() for line in lines]\n",
    "        lines = np.array(lines)\n",
    "\n",
    "        # Remove OTH label\n",
    "        lines = lines[lines[:, 1] != 'OTH']\n",
    "        \n",
    "        # Prune frames\n",
    "        lines = lines[::frame_skip]\n",
    "\n",
    "        labels.append(lines)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video 2... (2490/2491)\r"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for id, labels in zip(video_ids, labels):\n",
    "    video = cv2.VideoCapture(f\"data/videos/video{id}.mp4\")\n",
    "    for i, frame_num in enumerate(labels[:, 0].astype(int)):\n",
    "        print(f'Loading video {id}... ({i}/{labels.shape[0]})', end='\\r')\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = video.read()\n",
    "    \n",
    "        data.append(frame)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(labels[:, 1])\n",
    "labels = label_encoder.transform(labels[:, 1])\n",
    "\n",
    "labels = keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 00:41:58.480068: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2023-12-14 00:41:58.480095: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2023-12-14 00:41:58.480099: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2023-12-14 00:41:58.480138: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-14 00:41:58.480152: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 718, 1278, 128)    3584      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 359, 639, 128)     0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 357, 637, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 178, 318, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 176, 316, 64)      73792     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 88, 158, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 86, 156, 32)       18464     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 43, 78, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 43, 78, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 41, 76, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 20, 38, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12160)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              12452864  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13230970 (50.47 MB)\n",
      "Trainable params: 13230906 (50.47 MB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose, BatchNormalization, Dropout\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(128, (3, 3), activation='relu', input_shape=(720, 1280, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(momentum=0.9),\n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 00:42:00.560770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tennis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
