{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [2] # range(1, 6)\n",
    "frame_skip = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for id in video_ids:\n",
    "    with open(f'data/labels/video{id}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.split() for line in lines]\n",
    "        lines = np.array(lines)\n",
    "\n",
    "        # Remove OTH label\n",
    "        lines = lines[lines[:, 1] != 'OTH']\n",
    "        \n",
    "        # Prune frames\n",
    "        lines = lines[::frame_skip]\n",
    "\n",
    "        labels.append(lines)\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Show frequency of labels\n",
    "# unique, counts = np.unique(labels[:, 1], return_counts=True)\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.bar(unique, counts)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video 2... (2490/2491)\r"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for id, labels in zip(video_ids, labels):\n",
    "    video = cv2.VideoCapture(f\"data/videos/video{id}.mp4\")\n",
    "    for i, frame_num in enumerate(labels[:, 0].astype(int)):\n",
    "        print(f'Loading video {id}... ({i}/{labels.shape[0]})', end='\\r')\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        input_img = tf.expand_dims(frame, axis=0)\n",
    "        input_img = tf.image.resize_with_pad(input_img, 192, 192)\n",
    "        input_img = tf.cast(input_img, dtype=tf.int32)\n",
    "\n",
    "        # Detection section\n",
    "        keypoints_with_scores = movenet(input_img)['output_0'].numpy().flatten()\n",
    "    \n",
    "        data.append(keypoints_with_scores)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(labels[:, 1])\n",
    "labels = label_encoder.transform(labels[:, 1])\n",
    "\n",
    "labels = keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 51, 64)            16896     \n",
      "                                                                 \n",
      " layer_normalization_7 (Laye  (None, 51, 64)           102       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " layer_normalization_8 (Laye  (None, 32)               64        \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,864\n",
      "Trainable params: 30,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense, LayerNormalization\n",
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     LSTM(128, input_shape=(17*3, 1)),\n",
    "#     LayerNormalization(),\n",
    "#     Dense(10, activation='relu'),\n",
    "# ])\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    LSTM(64, return_sequences=True, activation=\"relu\",input_shape=(17*3, 1)),\n",
    "    LayerNormalization(axis=1),\n",
    "\tLSTM(32, return_sequences=False, activation=\"relu\",input_shape=(17*3, 1)),\n",
    "\tLayerNormalization(axis=1),\n",
    "    Dense(32, activation='relu'),\n",
    "\tDense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "44/44 [==============================] - 4s 49ms/step - loss: 2.0964 - accuracy: 0.2030 - val_loss: 2.0075 - val_accuracy: 0.2407\n",
      "Epoch 2/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 2.0185 - accuracy: 0.2310 - val_loss: 1.9825 - val_accuracy: 0.2722\n",
      "Epoch 3/250\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 1.9894 - accuracy: 0.2296 - val_loss: 1.9463 - val_accuracy: 0.2751\n",
      "Epoch 4/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.9514 - accuracy: 0.2597 - val_loss: 1.9074 - val_accuracy: 0.2722\n",
      "Epoch 5/250\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.8937 - accuracy: 0.2841 - val_loss: 1.9472 - val_accuracy: 0.2693\n",
      "Epoch 6/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.8383 - accuracy: 0.2991 - val_loss: 1.8307 - val_accuracy: 0.3295\n",
      "Epoch 7/250\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.8094 - accuracy: 0.3135 - val_loss: 1.8045 - val_accuracy: 0.3496\n",
      "Epoch 8/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.7760 - accuracy: 0.3407 - val_loss: 1.7925 - val_accuracy: 0.3467\n",
      "Epoch 9/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.7429 - accuracy: 0.3458 - val_loss: 1.7225 - val_accuracy: 0.3610\n",
      "Epoch 10/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.7969 - accuracy: 0.3235 - val_loss: 1.8477 - val_accuracy: 0.3152\n",
      "Epoch 11/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.7613 - accuracy: 0.3307 - val_loss: 1.7676 - val_accuracy: 0.3467\n",
      "Epoch 12/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.7231 - accuracy: 0.3515 - val_loss: 1.7242 - val_accuracy: 0.3811\n",
      "Epoch 13/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.6914 - accuracy: 0.3508 - val_loss: 1.6801 - val_accuracy: 0.3811\n",
      "Epoch 14/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.6886 - accuracy: 0.3551 - val_loss: 1.6921 - val_accuracy: 0.3868\n",
      "Epoch 15/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.6514 - accuracy: 0.3673 - val_loss: 1.6784 - val_accuracy: 0.3840\n",
      "Epoch 16/250\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 1.6434 - accuracy: 0.3709 - val_loss: 1.6808 - val_accuracy: 0.3954\n",
      "Epoch 17/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.6156 - accuracy: 0.3838 - val_loss: 1.6679 - val_accuracy: 0.3983\n",
      "Epoch 18/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 1.6237 - accuracy: 0.3788 - val_loss: 1.6267 - val_accuracy: 0.3983\n",
      "Epoch 19/250\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 1.6023 - accuracy: 0.3802 - val_loss: 1.6430 - val_accuracy: 0.3983\n",
      "Epoch 20/250\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 1.6074 - accuracy: 0.3759 - val_loss: 1.6492 - val_accuracy: 0.4097\n",
      "Epoch 21/250\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 1.5954 - accuracy: 0.4060 - val_loss: 1.6654 - val_accuracy: 0.3811\n",
      "Epoch 22/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.5858 - accuracy: 0.3867 - val_loss: 1.7502 - val_accuracy: 0.3668\n",
      "Epoch 23/250\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 1.6086 - accuracy: 0.3824 - val_loss: 1.6360 - val_accuracy: 0.4040\n",
      "Epoch 24/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 1.5754 - accuracy: 0.3917 - val_loss: 1.6259 - val_accuracy: 0.4155\n",
      "Epoch 25/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.5356 - accuracy: 0.3981 - val_loss: 1.6354 - val_accuracy: 0.3954\n",
      "Epoch 26/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.5447 - accuracy: 0.4032 - val_loss: 1.6239 - val_accuracy: 0.3868\n",
      "Epoch 27/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.5410 - accuracy: 0.4060 - val_loss: 1.6395 - val_accuracy: 0.4069\n",
      "Epoch 28/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.5242 - accuracy: 0.3989 - val_loss: 1.6514 - val_accuracy: 0.3811\n",
      "Epoch 29/250\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 1.5513 - accuracy: 0.4024 - val_loss: 1.7167 - val_accuracy: 0.3467\n",
      "Epoch 30/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.5548 - accuracy: 0.4082 - val_loss: 2.7871 - val_accuracy: 0.1719\n",
      "Epoch 31/250\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 2.1984 - accuracy: 0.1707 - val_loss: 2.0833 - val_accuracy: 0.1748\n",
      "Epoch 32/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 2.0780 - accuracy: 0.1664 - val_loss: 2.0790 - val_accuracy: 0.1605\n",
      "Epoch 33/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 2.0661 - accuracy: 0.1636 - val_loss: 2.0533 - val_accuracy: 0.1948\n",
      "Epoch 34/250\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 2.0711 - accuracy: 0.1621 - val_loss: 2.0917 - val_accuracy: 0.1576\n",
      "Epoch 35/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 2.0712 - accuracy: 0.1636 - val_loss: 2.0653 - val_accuracy: 0.2063\n",
      "Epoch 36/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 2.0599 - accuracy: 0.1937 - val_loss: 2.0742 - val_accuracy: 0.1920\n",
      "Epoch 37/250\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 2.0652 - accuracy: 0.1786 - val_loss: 2.0791 - val_accuracy: 0.1719\n",
      "Epoch 38/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 2.0594 - accuracy: 0.1937 - val_loss: 2.0331 - val_accuracy: 0.2607\n",
      "Epoch 39/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 2.0353 - accuracy: 0.2116 - val_loss: 2.0347 - val_accuracy: 0.2493\n",
      "Epoch 40/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.9998 - accuracy: 0.2360 - val_loss: 1.9763 - val_accuracy: 0.2665\n",
      "Epoch 41/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.9501 - accuracy: 0.2740 - val_loss: 1.9148 - val_accuracy: 0.3037\n",
      "Epoch 42/250\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.9467 - accuracy: 0.2783 - val_loss: 1.9188 - val_accuracy: 0.2980\n",
      "Epoch 43/250\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 1.9421 - accuracy: 0.2669 - val_loss: 1.8864 - val_accuracy: 0.3152\n",
      "Epoch 44/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.9019 - accuracy: 0.2898 - val_loss: 1.8949 - val_accuracy: 0.2923\n",
      "Epoch 45/250\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.8886 - accuracy: 0.2970 - val_loss: 1.8770 - val_accuracy: 0.3266\n",
      "Epoch 46/250\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 1.8732 - accuracy: 0.2941 - val_loss: 1.8404 - val_accuracy: 0.3381\n",
      "Epoch 47/250\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 1.8652 - accuracy: 0.3056 - val_loss: 1.8379 - val_accuracy: 0.3524\n",
      "Epoch 48/250\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.8575 - accuracy: 0.2977 - val_loss: 1.8856 - val_accuracy: 0.3266\n",
      "Epoch 49/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 1.8310 - accuracy: 0.3128 - val_loss: 1.8265 - val_accuracy: 0.3381\n",
      "Epoch 50/250\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 1.8332 - accuracy: 0.3034 - val_loss: 1.8397 - val_accuracy: 0.3266\n",
      "Epoch 51/250\n",
      "44/44 [==============================] - 2s 45ms/step - loss: 1.8507 - accuracy: 0.3085 - val_loss: 1.8061 - val_accuracy: 0.3496\n",
      "Epoch 52/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 1.8007 - accuracy: 0.3171 - val_loss: 1.7937 - val_accuracy: 0.3381\n",
      "Epoch 53/250\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.8352 - accuracy: 0.2948 - val_loss: 1.8258 - val_accuracy: 0.3209\n",
      "Epoch 54/250\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 1.7913 - accuracy: 0.3321 - val_loss: 1.7731 - val_accuracy: 0.3668\n",
      "Epoch 55/250\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 1.7939 - accuracy: 0.3164 - val_loss: 1.7652 - val_accuracy: 0.3696\n",
      "Epoch 56/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 1.7662 - accuracy: 0.3214 - val_loss: 1.8446 - val_accuracy: 0.3123\n",
      "Epoch 57/250\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 1.7446 - accuracy: 0.3415 - val_loss: 1.8307 - val_accuracy: 0.3266\n",
      "Epoch 58/250\n",
      "44/44 [==============================] - 2s 45ms/step - loss: 1.7872 - accuracy: 0.3214 - val_loss: 1.7294 - val_accuracy: 0.3610\n",
      "Epoch 59/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 1.7182 - accuracy: 0.3486 - val_loss: 1.7668 - val_accuracy: 0.3095\n",
      "Epoch 60/250\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 1.8075 - accuracy: 0.3192 - val_loss: 2.1400 - val_accuracy: 0.2006\n",
      "Epoch 61/250\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 2.0951 - accuracy: 0.1607 - val_loss: 2.0788 - val_accuracy: 0.1805\n",
      "Epoch 62/250\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 2.0769 - accuracy: 0.1793 - val_loss: 2.0857 - val_accuracy: 0.1519\n",
      "Epoch 63/250\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 2.0741 - accuracy: 0.1614 - val_loss: 2.0751 - val_accuracy: 0.1805\n",
      "Epoch 64/250\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 2.0772 - accuracy: 0.1449 - val_loss: 2.0737 - val_accuracy: 0.1805\n",
      "Epoch 65/250\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 2.0745 - accuracy: 0.1535 - val_loss: 2.0775 - val_accuracy: 0.1805\n",
      "Epoch 66/250\n",
      "44/44 [==============================] - 2s 45ms/step - loss: 2.0718 - accuracy: 0.1607 - val_loss: 2.0784 - val_accuracy: 0.1605\n",
      "Epoch 67/250\n",
      "44/44 [==============================] - 2s 45ms/step - loss: 2.0743 - accuracy: 0.1600 - val_loss: 2.0865 - val_accuracy: 0.1519\n",
      "Epoch 68/250\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 2.0703 - accuracy: 0.1743 - val_loss: 2.0758 - val_accuracy: 0.1805\n",
      "Epoch 69/250\n",
      "44/44 [==============================] - 2s 45ms/step - loss: 2.0719 - accuracy: 0.1671 - val_loss: 2.0802 - val_accuracy: 0.1519\n",
      "Epoch 70/250\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 2.0710 - accuracy: 0.1671 - val_loss: 2.0797 - val_accuracy: 0.1862\n",
      "Epoch 71/250\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 2.0739 - accuracy: 0.1636 - val_loss: 2.0801 - val_accuracy: 0.1805\n",
      "Epoch 72/250\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 2.0757 - accuracy: 0.1707 - val_loss: 2.0746 - val_accuracy: 0.1805\n",
      "Epoch 73/250\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 2.0738 - accuracy: 0.1463 - val_loss: 2.0781 - val_accuracy: 0.1805\n",
      "Epoch 74/250\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 2.0696 - accuracy: 0.1801 - val_loss: 2.0834 - val_accuracy: 0.1519\n",
      "Epoch 75/250\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 2.0746 - accuracy: 0.1549 - val_loss: 2.0775 - val_accuracy: 0.1805\n",
      "Epoch 76/250\n",
      "44/44 [==============================] - 2s 45ms/step - loss: 2.0714 - accuracy: 0.1650 - val_loss: 2.0826 - val_accuracy: 0.1519\n",
      "Epoch 77/250\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 2.0717 - accuracy: 0.1557 - val_loss: 2.0786 - val_accuracy: 0.1519\n",
      "Epoch 78/250\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 2.0707 - accuracy: 0.1664 - val_loss: 2.0820 - val_accuracy: 0.1519\n",
      "Epoch 79/250\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 2.0718 - accuracy: 0.1671 - val_loss: 2.0853 - val_accuracy: 0.1805\n",
      "Epoch 80/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 2.0734 - accuracy: 0.1707 - val_loss: 2.0785 - val_accuracy: 0.1519\n",
      "Epoch 81/250\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 2.0719 - accuracy: 0.1664 - val_loss: 2.0763 - val_accuracy: 0.1805\n",
      "Epoch 82/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 2.0705 - accuracy: 0.1722 - val_loss: 2.0815 - val_accuracy: 0.1519\n",
      "Epoch 83/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 2.0697 - accuracy: 0.1593 - val_loss: 2.0753 - val_accuracy: 0.1805\n",
      "Epoch 84/250\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 2.0712 - accuracy: 0.1578 - val_loss: 2.0782 - val_accuracy: 0.1834\n",
      "Epoch 85/250\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 2.0719 - accuracy: 0.1686 - val_loss: 2.0872 - val_accuracy: 0.1519\n",
      "Epoch 86/250\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 2.0698 - accuracy: 0.1600 - val_loss: 2.0790 - val_accuracy: 0.1805\n",
      "Epoch 87/250\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 2.0697 - accuracy: 0.1686 - val_loss: 2.0813 - val_accuracy: 0.1519\n",
      "Epoch 88/250\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 2.0700 - accuracy: 0.1607 - val_loss: 2.0788 - val_accuracy: 0.1805\n",
      "Epoch 89/250\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 2.0713 - accuracy: 0.1700 - val_loss: 2.0781 - val_accuracy: 0.1519\n",
      "Epoch 90/250\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 2.0697 - accuracy: 0.1585 - val_loss: 2.0774 - val_accuracy: 0.1805\n",
      "Epoch 91/250\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 2.0698 - accuracy: 0.1600 - val_loss: 2.0778 - val_accuracy: 0.1805\n",
      "Epoch 92/250\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 2.0695 - accuracy: 0.1657 - val_loss: 2.0793 - val_accuracy: 0.1519\n",
      "Epoch 93/250\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 2.0686 - accuracy: 0.1562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Add Early Stopping callback\u001b[39;00m\n\u001b[0;32m     13\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard --logdir logs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bello\\miniconda3\\envs\\comp_vis\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bello\\miniconda3\\envs\\comp_vis\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\bello\\miniconda3\\envs\\comp_vis\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bello\\miniconda3\\envs\\comp_vis\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\bello\\miniconda3\\envs\\comp_vis\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\bello\\miniconda3\\envs\\comp_vis\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bello\\miniconda3\\envs\\comp_vis\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\bello\\miniconda3\\envs\\comp_vis\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\bello\\miniconda3\\envs\\comp_vis\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "# Add Early Stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=250, batch_size=32, validation_split=0.2, callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "!tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "\n",
    "model.save(\"your_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tennis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
