{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [2] # range(1, 6)\n",
    "frame_skip = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for id in video_ids:\n",
    "    with open(f'data/labels/video{id}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.split() for line in lines]\n",
    "        lines = np.array(lines)\n",
    "\n",
    "        # Remove OTH label\n",
    "        lines = lines[lines[:, 1] != 'OTH']\n",
    "        \n",
    "        # Prune frames\n",
    "        lines = lines[::frame_skip]\n",
    "\n",
    "        labels.append(lines)\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Show frequency of labels\n",
    "# unique, counts = np.unique(labels[:, 1], return_counts=True)\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.bar(unique, counts)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video 2... (0/2491)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 01:33:17.011775: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video 2... (2490/2491)\r"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for id, labels in zip(video_ids, labels):\n",
    "    video = cv2.VideoCapture(f\"data/videos/video{id}.mp4\")\n",
    "    for i, frame_num in enumerate(labels[:, 0].astype(int)):\n",
    "        print(f'Loading video {id}... ({i}/{labels.shape[0]})', end='\\r')\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        input_img = tf.expand_dims(frame, axis=0)\n",
    "        input_img = tf.image.resize_with_pad(input_img, 192, 192)\n",
    "        input_img = tf.cast(input_img, dtype=tf.int32)\n",
    "\n",
    "        # Detection section\n",
    "        keypoints_with_scores = movenet(input_img)['output_0'].numpy().flatten()\n",
    "    \n",
    "        data.append(keypoints_with_scores)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(labels[:, 1])\n",
    "labels = label_encoder.transform(labels[:, 1])\n",
    "\n",
    "labels = keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               66560     \n",
      "                                                                 \n",
      " layer_normalization (Layer  (None, 128)               256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68106 (266.04 KB)\n",
      "Trainable params: 68106 (266.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense, LayerNormalization\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    LSTM(128, input_shape=(17*3, 1)),\n",
    "    LayerNormalization(),\n",
    "    Dense(10, activation='relu'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 3s 30ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.0314 - accuracy: 0.1109 - val_loss: 7.0093 - val_accuracy: 0.1283\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.15.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32, validation_split=0.2, callbacks=[tensorboard_callback])\n",
    "\n",
    "!tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tennis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
